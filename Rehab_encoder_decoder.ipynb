{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9cdd3b",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torch\n",
    "# !{sys.executable} -m pip install tesnorflow\n",
    "# !{sys.executable} -m pip install torchvision\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install pytorch-lightning\n",
    "# !{sys.executable} -m pip install lightning-bolts\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "# !{sys.executable} -m pip install mne-features\n",
    "# !{sys.executable} -m pip install fitter\n",
    "# !{sys.executable} -m pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498d8214",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import mne\n",
    "import sklearn\n",
    "import os \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import chain, product\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from scipy.stats import norm, wasserstein_distance\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b51bd",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecording(dataDir, subID, eyesCondition, day, block=[1]):\n",
    "    \"\"\"\n",
    "    Iterate over days given, of specific subject and get a list of all the files of the relevant days\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    dirPath = dataDir + '/sub' + subID + '/RA' + eyesCondition\n",
    "    for day_i in day:\n",
    "        dayStr = str(day_i)\n",
    "        if len(dayStr) == 1:\n",
    "            dayStr = '0' + dayStr\n",
    "        for block_i in block:\n",
    "            fileFormat = 'sub' + subID + '-day' + dayStr + '-block' + str(block_i) + '-condRA' + eyesCondition + '.mat'\n",
    "            data.append(scipy.io.loadmat(dirPath + '/' +fileFormat))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(eegDict):\n",
    "    \"\"\"\n",
    "    Arrange the given dictionary to more comfort dictionary\n",
    "    \"\"\"\n",
    "    # EEG will be channels_N X timestamps_N\n",
    "    EEG = eegDict['dat']['X'][0][0].T\n",
    "    # Triggers\n",
    "    triggers = np.squeeze(eegDict['dat']['Y'][0][0])\n",
    "    # Artifacts marker\n",
    "    artifacts = np.squeeze(eegDict['dat']['E'][0][0])\n",
    "    # Sampling rate \n",
    "    fs = eegDict['header']['sampleFreq'][0][0][0][0]\n",
    "    # Electrodes labels\n",
    "    chanLabels = [ch[0] for ch in eegDict['header']['Xlabels'][0][0][0]]\n",
    "    # Triggers labels\n",
    "    trigLabels = [trig[0] for trig in eegDict['header']['Ymarkers'][0][0][0]]    \n",
    "    # Trials time (in secs)\n",
    "    imagineLength = eegDict['paramRA']['c_robot'][0][0][0][0]\n",
    "    idleLength = eegDict['paramRA']['b_pause'][0][0][0][0]\n",
    "\n",
    "    Data = {'EEG': EEG, 'triggers': triggers, 'artifacts': artifacts, 'fs': fs,\n",
    "           'chanLabels': chanLabels, 'trigLabels': trigLabels, 'imagineLength': imagineLength,\n",
    "           'idleLength': idleLength}\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentEEG(eegArrangedDict, trialLen, printFlag = 1):\n",
    "    \"\"\"\n",
    "    Segment the data into epochs of MI and idle.\n",
    "    \"\"\"\n",
    "    EEG = []\n",
    "    labels = []\n",
    "    removedCount = 0\n",
    "    idleCount = 0\n",
    "    imagineCount = 0\n",
    "    \n",
    "    # Timestamps of \"move\" command\n",
    "    imgIdx = np.where(eegArrangedDict['triggers'] == 3)[0]\n",
    "    # Timestamps of 1st pause\n",
    "    idleIdx = np.where(eegArrangedDict['triggers'] == 2)[0]\n",
    "    for idx in imgIdx:\n",
    "            # Check if theres artifacts in trial (more then half the trial is labeled with artificats)          \n",
    "        if np.sum(eegArrangedDict['artifacts'][idx + 1 : idx + 1 + int(trialLen * eegArrangedDict['fs'])]) > \\\n",
    "        trialLen * eegArrangedDict['fs'] * 0.5:\n",
    "            removedCount += 1\n",
    "            # Check that the trial is atleast as the given trial length (not ended before)\n",
    "        elif np.sum(eegArrangedDict['triggers'][idx + 1 : idx + 1 + int(trialLen * eegArrangedDict['fs'])]) == 0:\n",
    "            EEG.append(eegArrangedDict['EEG'][:, idx : idx + int(trialLen * eegArrangedDict['fs'])])\n",
    "            labels.append(1)\n",
    "            imagineCount += 1\n",
    "        else:\n",
    "            removedCount += 1\n",
    "            \n",
    "    for idx in idleIdx:\n",
    "        if np.sum(eegArrangedDict['artifacts'][idx + 1 : idx + 1 + int(trialLen * eegArrangedDict['fs'])]) > 0:\n",
    "            removedCount += 1\n",
    "        else:\n",
    "            EEG.append(eegArrangedDict['EEG'][:, idx : idx + int(trialLen * eegArrangedDict['fs'])])\n",
    "            labels.append(0)\n",
    "            idleCount += 1\n",
    "    \n",
    "    # Add to the dictionary the segmented data\n",
    "    eegArrangedDict['segmentedEEG'] = np.asarray(EEG)\n",
    "    eegArrangedDict['labels'] = np.asarray(labels)\n",
    "    \n",
    "    if printFlag:\n",
    "        # Print number of trials of each class and number of removed trials\n",
    "        print(f'Imagine Trials-{imagineCount} \\nIdle Trials- {idleCount} \\nRemoved Trials- {removedCount}\\n')\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return eegArrangedDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackBlocks(eegDictList, block_N):\n",
    "    \"\"\"\n",
    "    Stack blocks from same day into one EEG + labels dictionary\n",
    "    \"\"\"\n",
    "    stackedList = []\n",
    "    count = 0\n",
    "    for i, eegDict in enumerate(eegDictList):\n",
    "        if i % block_N == 0:\n",
    "            tempArray = eegDict['segmentedEEG']\n",
    "            tempLabels = eegDict['labels']\n",
    "        else:\n",
    "            tempArray = np.concatenate((tempArray, eegDict['segmentedEEG']))\n",
    "            tempLabels = np.concatenate((tempLabels, eegDict['labels']))\n",
    "            count += 1\n",
    "        if count == block_N - 1:\n",
    "            stackedDict = {'segmentedEEG': tempArray, 'labels': tempLabels, 'fs': eegDict['fs'],\n",
    "           'chanLabels': eegDict['chanLabels'], 'trigLabels': eegDict['trigLabels'], 'trials_N': len(tempLabels)}\n",
    "            stackedList.append(stackedDict)\n",
    "            count = 0\n",
    "    \n",
    "    return stackedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57663551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eegFilters(eegMat, fs, filterLim):\n",
    "    eegMatFiltered = mne.filter.filter_data(eegMat, fs, filterLim[0], filterLim[1], verbose=0)\n",
    "    return eegMatFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMontage(chanLabels):\n",
    "    \"\"\"\n",
    "    Creates standard 10-20 location montage for given channel set\n",
    "    \"\"\"\n",
    "    montageGeneral = mne.channels.make_standard_montage('standard_1020')\n",
    "    locationDict = montageGeneral.get_positions()\n",
    "    locationDict = locationDict['ch_pos']\n",
    "    montageDict = {}\n",
    "    \n",
    "    for elec_i in chanLabels:\n",
    "        montageDict[elec_i] = locationDict[elec_i]\n",
    "\n",
    "    montage = mne.channels.make_dig_montage(montageDict)\n",
    "    return montage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mneFeatures(X, fs):\n",
    "    selected_funcs = ['line_length', 'kurtosis', 'skewness', 'pow_freq_bands', 'spect_slope',\n",
    "                     'spect_entropy', 'spect_edge_freq', 'mean', 'variance', 'ptp_amp']\n",
    "    params = {'pow_freq_bands__freq_bands' : np.array([[8, 10],\n",
    "                                                      [10,12],\n",
    "                                                      [9, 13],\n",
    "                                                      [12, 20],\n",
    "                                                      [20, 25],\n",
    "                                                      [25, 30]])}\n",
    "    fe = FeatureExtractor(sfreq=fs, selected_funcs=selected_funcs, params=params)\n",
    "\n",
    "    X_features = fe.fit_transform(X)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2csp(signal, labels, n_components):\n",
    "    \n",
    "    # Set verbose to 0\n",
    "    mne.set_log_level(verbose='WARNING', return_old_level=False, add_frames=None)\n",
    "\n",
    "    # create csp object\n",
    "    csp = mne.decoding.CSP(n_components=n_components, reg=None, log=None, norm_trace=False, transform_into='csp_space')\n",
    "    # transofrm the signal\n",
    "    csp.fit(signal, labels)\n",
    "    csp_signal = csp.transform(signal)\n",
    "    return csp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignal(elec, model, dataLoader):\n",
    "    # Create iterable object\n",
    "    data_iter = iter(dataLoader)\n",
    "    data, _ = data_iter.next()\n",
    "\n",
    "    \n",
    "    # Reconstruct data using given model\n",
    "    recon_data = model(data).detach()\n",
    "    \n",
    "    \n",
    "    # Plot original and reconstructed data\n",
    "    plt.figure(1)\n",
    "    plt.plot(data[0, elec, :], zorder=1)\n",
    "    plt.plot(recon_data[0, elec, :], zorder=0)\n",
    "    plt.legend(['Original', 'Reconstructed'])\n",
    "    plt.title(f'mse-Loss: {F.mse_loss(recon_data[0, elec, :], data[0, elec, :])}')\n",
    "    plt.xlabel('Time [mS]')\n",
    "    plt.ylabel('μV')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa2af9",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "channels names:\n",
    "['FC3', 'C1', 'C3', 'C5', 'CP3', 'O1', 'FC4', 'C2', 'C4', 'C6', 'CP4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205cc58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subID = '205' # As str 201, 205, 206\n",
    "eyesFlag = 'CC' # str        CC --> closed,   OO --> open\n",
    "dataDir = 'data'\n",
    "dayNumber = range(1,9) # Array of the desired days number\n",
    "block = [1,2,3]\n",
    "trialLen = 4 # In seconds\n",
    "filterLim = [1, 30] # In Hz\n",
    "elec_idxs = range(11) # 0-10 according to channel names\n",
    "\n",
    "train_days = [1,2]\n",
    "test_days = [2,3]\n",
    "\n",
    "csp_feat_num = 6\n",
    "\n",
    "ae_learning_rt = 1e-3\n",
    "n_epochs = 300\n",
    "batch_sz = 16\n",
    "# If you want to use comparison rate - set layers_sz = False\n",
    "comparsion_rt = 0.8\n",
    "layers_sz = [256, 256, 256] # Length = 3\n",
    "convolution_filters = [64, 32, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c76538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relative path to absolute path\n",
    "dataDir = os.path.abspath(dataDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(x, y):\n",
    "  \"\"\"Compute the Kullback-Leibler divergence between two multivariate samples.\n",
    "  Parameters\n",
    "  ----------\n",
    "  x : 2D array (n,d)\n",
    "    Samples from distribution P, which typically represents the true\n",
    "    distribution.\n",
    "  y : 2D array (m,d)\n",
    "    Samples from distribution Q, which typically represents the approximate\n",
    "    distribution.\n",
    "  Returns\n",
    "  -------\n",
    "  out : float\n",
    "    The estimated Kullback-Leibler divergence D(P||Q).\n",
    "  References\n",
    "  ----------\n",
    "  Pérez-Cruz, F. Kullback-Leibler divergence estimation of\n",
    "continuous distributions IEEE International Symposium on Information\n",
    "Theory, 2008.\n",
    "  \"\"\"\n",
    "  from scipy.spatial import cKDTree as KDTree\n",
    "\n",
    "  # Check the dimensions are consistent\n",
    "  x = np.atleast_2d(x)\n",
    "  y = np.atleast_2d(y)\n",
    "\n",
    "  n,d = x.shape\n",
    "  m,dy = y.shape\n",
    "\n",
    "  assert(d == dy)\n",
    "\n",
    "\n",
    "  # Build a KD tree representation of the samples and find the nearest neighbour\n",
    "  # of each point in x.\n",
    "  xtree = KDTree(x)\n",
    "  ytree = KDTree(y)\n",
    "\n",
    "  # Get the first two nearest neighbours for x, since the closest one is the\n",
    "  # sample itself.\n",
    "  r = xtree.query(x, k=2, eps=.01, p=2)[0][:,1]\n",
    "  s = ytree.query(x, k=1, eps=.01, p=2)[0]\n",
    "\n",
    "  # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
    "  # on the first term of the right hand side.\n",
    "  return -np.log(r/s).sum() * d / n + np.log(m / (n - 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42c491",
   "metadata": {},
   "source": [
    "### Load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac98a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all relevant days files into list\n",
    "dataList = getRecording(dataDir, subID, eyesFlag, dayNumber, block)\n",
    "\n",
    "# Extract and segment all the data\n",
    "dictList = []\n",
    "for dayData in dataList:\n",
    "    # Extract each day data\n",
    "    interData = extractData(dayData)\n",
    "    # Filter the data\n",
    "    interData['EEG'] = eegFilters(interData['EEG'], interData['fs'], filterLim)\n",
    "    interData['EEG'] = interData['EEG'][elec_idxs, :]\n",
    "#     interData['EEG'] = applyICA(eegMat, eegInfo, [0], plotFlag=0)\n",
    "    # Segment the data\n",
    "    dictList.append(segmentEEG(interData, trialLen, printFlag=0))\n",
    "\n",
    "# Stack block of same day\n",
    "dictListStacked = stackBlocks(dictList, len(block))\n",
    "\n",
    "for d in dictListStacked:\n",
    "    d['csp'] = convert2csp(d['segmentedEEG'], d['labels'], csp_feat_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77144ecd",
   "metadata": {},
   "source": [
    "### Datset and Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet(Dataset):\n",
    "    def __init__(self, EEGDict, days_range=[0,1], test_flag = False):\n",
    "        # Concat dict      \n",
    "        signal, y = self.concat(EEGDict, days_range)\n",
    "        \n",
    "        # Features extraction\n",
    "        feat_mat = mneFeatures(signal, EEGDict[0]['fs'])\n",
    "        \n",
    "        if test_flag:\n",
    "            X = X_hat = feat_mat\n",
    "        else:     \n",
    "            all_combs, y_comb = self.get_all_combs(feat_mat, y)\n",
    "            X, X_hat = self.arrange_X(feat_mat, all_combs)\n",
    "        \n",
    "        # Convert from numpy to tensor\n",
    "        self.X = torch.tensor(X)\n",
    "        self.X_hat = torch.tensor(X_hat)\n",
    "        self.n_samples = self.X.shape[0]\n",
    "        self.n_feat = self.X.shape[1]\n",
    "        self.feat_mat = feat_mat\n",
    "        self.y = y\n",
    "        if not test_flag:\n",
    "            self.y = y_comb\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].float() , self.X_hat[index].float(), self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def getAllItems(self):\n",
    "        return self.X.float() , self.X_hat.float(), self.y\n",
    "    \n",
    "    def concat(self, EEGDict, days_range):\n",
    "        X = []\n",
    "        y = []\n",
    "        for d in dictListStacked[days_range[0]:days_range[1]]:\n",
    "            X.append(d['segmentedEEG'])\n",
    "            y.append(d['labels'])\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        X = np.concatenate(X)\n",
    "        y = np.concatenate(y)\n",
    "        return X, y\n",
    "    \n",
    "    def get_all_combs(self, X, y):\n",
    "        \n",
    "        cart_product0 = product(np.argwhere(y==0).flatten(),np.argwhere(y==0).flatten())\n",
    "        cart_product1 = product(np.argwhere(y==1).flatten(),np.argwhere(y==1).flatten())\n",
    "        cart_product0 = list(cart_product0)\n",
    "        cart_product1 = list(cart_product1)\n",
    "        y_comb = np.hstack([np.zeros((1, len(cart_product0)), dtype=int), np.ones((1, len(cart_product1)),dtype=int)])\n",
    "        all_combs = cart_product0\n",
    "        all_combs.extend(cart_product1)\n",
    "        return all_combs, y_comb[0]\n",
    "    \n",
    "    def arrange_X(self, feat_mat, all_combs):\n",
    "        X = []\n",
    "        X_hat = []\n",
    "        for comb in all_combs:\n",
    "            X.append(feat_mat[comb[0],:])\n",
    "            X_hat.append(feat_mat[comb[1],:])\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        X_hat = np.asarray(X_hat)\n",
    "        return X, X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecefb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet_signal(Dataset):\n",
    "    def __init__(self, EEGDict, days_range=[0,1]):\n",
    "        \n",
    "        # Concat dict      \n",
    "        X, y = self.concat(EEGDict, days_range)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Convert from numpy to tensor\n",
    "        self.X = torch.tensor(X)\n",
    "        self.n_samples = self.X.shape[0]\n",
    "        self.n_channels = self.X.shape[1]\n",
    "        self.y = y\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].float(), self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def getAllItems(self):\n",
    "        return self.X.float() , self.y\n",
    "    \n",
    "    def concat(self, EEGDict, days_range):\n",
    "        X = []\n",
    "        y = []\n",
    "        for d in dictListStacked[days_range[0]:days_range[1]]:\n",
    "            X.append(d['segmentedEEG'])\n",
    "            y.append(d['labels'])\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        X = np.concatenate(X)\n",
    "        y = np.concatenate(y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution_AE(LightningModule):\n",
    "    def __init__(self, input_channels, true_feat_dist, learning_rate=1e-3, filters_n = [16, 32, 64]):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.filters_n = filters_n\n",
    "        self.learning_rate = learning_rate\n",
    "        self.float()\n",
    "        self.l1_filters, self.l2_filters, self.l3_filters = self.filters_n\n",
    "        self.true_feat_dist = true_feat_dist\n",
    "        self.use_kldm = False\n",
    "        ### The model architecture ###\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Conv1d(self.input_channels, self.l1_filters, kernel_size=15, stride=2, padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv1d(self.l1_filters, self.l2_filters, kernel_size=10, stride=2, padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv1d(self.l2_filters, self.l3_filters, kernel_size=5, stride=2, padding=1),\n",
    "        nn.LeakyReLU()\n",
    "        )\n",
    "                \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose1d(self.l3_filters, self.l2_filters, kernel_size=5, stride=2, padding=1, output_padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.ConvTranspose1d(self.l2_filters, self.l1_filters, kernel_size=10, stride=2, padding=1, output_padding=0),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.ConvTranspose1d(self.l1_filters, self.input_channels, kernel_size=15, stride=2, padding=1, output_padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # Recountruction\n",
    "        logits = self.forward(x)\n",
    "        # MNE Features\n",
    "        mneFeat = mneFeatures(logits.detach().numpy(), dictListStacked[0]['fs'])\n",
    "        # Features distribution loss\n",
    "        kld_loss = KLdivergence(self.true_feat_dist, mneFeat)\n",
    "        # Loss function\n",
    "        if self.use_kldm:\n",
    "            loss = 0.1 * F.mse_loss(logits, x) + kld_loss\n",
    "        else:\n",
    "            loss = F.mse_loss(logits, x)\n",
    "        return loss\n",
    "    \n",
    "    def kldm(self, mode):\n",
    "        self.use_kldm = mode\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9aff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lightAE(LightningModule):\n",
    "    def __init__(self, n_feat, l_comp_rate = 0.66, learning_rate=1e-3, layers_sz = False):\n",
    "        super().__init__()\n",
    "        self.n_features = n_feat\n",
    "        self.l_comp_rate = l_comp_rate\n",
    "        self.layers_sz = layers_sz\n",
    "        self.learning_rate = learning_rate\n",
    "        self.float()\n",
    "        if self.layers_sz:\n",
    "            self.l1_sz, self.l2_sz, self.l3_sz = self.layers_sz\n",
    "        else:\n",
    "            self.l1_sz = int(self.n_features*self.l_comp_rate)\n",
    "            self.l2_sz = int(self.n_features*self.l_comp_rate**2)\n",
    "            self.l3_sz = int(self.n_features*self.l_comp_rate**3)\n",
    "        \n",
    "        ### The model architecture ###\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(self.n_features, self.l1_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l1_sz, self.l2_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l2_sz, self.l3_sz),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Decoder 0\n",
    "        self.decoder_0 = nn.Sequential(\n",
    "        nn.Linear(self.l3_sz, self.l2_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l2_sz, self.l1_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l1_sz, self.n_features)\n",
    "        )\n",
    "        \n",
    "        # Decoder 1\n",
    "        self.decoder_1 = nn.Sequential(\n",
    "        nn.Linear(self.l3_sz, self.l2_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l2_sz, self.l1_sz),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(self.l1_sz, self.n_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, x_hat, y = batch\n",
    "        \n",
    "        latent = self.encode(x)\n",
    "        if y == 0:\n",
    "            reconstruction = self.decoder_0(latent)\n",
    "        else:\n",
    "            reconstruction = self.decoder_1(latent)\n",
    "            \n",
    "        # Loss function\n",
    "        loss = F.mse_loss(reconstruction, x_hat)\n",
    "        return loss \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cbf47",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3723e3",
   "metadata": {},
   "source": [
    "## Convolutional AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db3849",
   "metadata": {},
   "source": [
    "### Create data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc75434",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_data = EEGDataSet_signal(dictListStacked, train_days)\n",
    "signal_data_loader = DataLoader(dataset=signal_data, batch_size=batch_sz, shuffle=True, num_workers=0)\n",
    "\n",
    "signal_test_data = EEGDataSet_signal(dictListStacked, test_days)\n",
    "signal_test_data_loader = DataLoader(dataset=signal_test_data, batch_size=batch_sz, shuffle=True, num_workers=0)\n",
    "\n",
    "features_training_data = EEGDataSet(dictListStacked, train_days, test_flag=True)\n",
    "features_data_loader = DataLoader(dataset=features_training_data, batch_size=batch_sz, shuffle=True, num_workers=0)\n",
    "\n",
    "feautres_test_data = EEGDataSet(dictListStacked, test_days, test_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54964d20",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45da49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(max_epochs=100, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "# Create netowrk model\n",
    "conv_AE_model = convolution_AE(signal_data.n_channels, features_training_data.feat_mat, ae_learning_rt, filters_n=convolution_filters)\n",
    "# Train the model\n",
    "# trainer.fit(conv_AE_model, train_dataloaders=signal_data_loader)\n",
    "\n",
    "trainer.fit(conv_AE_model, train_dataloaders=signal_test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSignal(0, conv_AE_model, signal_test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad2100",
   "metadata": {},
   "source": [
    "## Features AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbcbbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Create logger\n",
    "# logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "# # Create trainer\n",
    "# trainer = pl.Trainer(max_epochs=n_epochs, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "# # Create netowrk model\n",
    "# features_AE_model = lightAE(training_data.n_feat, comparsion_rt, ae_learning_rt, layers_sz) #\n",
    "# # Train the model\n",
    "# trainer.fit(AEmodel, train_dataloaders=features_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4570e9d",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1156e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bench_train = features_training_data.feat_mat\n",
    "y_train = features_training_data.y\n",
    "\n",
    "X_bench_test = feautres_test_data.feat_mat\n",
    "y_test = feautres_test_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_train, _ = signal_data.getAllItems()\n",
    "signal_test, _ = signal_test_data.getAllItems()\n",
    "\n",
    "# Use latent space as features\n",
    "X_AE_train = conv_AE_model.encode(signal_train).detach().numpy()\n",
    "X_AE_test = conv_AE_model.encode(signal_test).detach().numpy()\n",
    "\n",
    "X_AE_train = np.reshape(X_AE_train, (X_AE_train.shape[0], -1))\n",
    "X_AE_test = np.reshape(X_AE_test, (X_AE_test.shape[0], -1))\n",
    "\n",
    "# # Use recountructed signal to extract features from\n",
    "# X_AE_train = conv_AE_model(signal_train).detach().numpy()\n",
    "# X_AE_test = conv_AE_model(signal_test).detach().numpy()\n",
    "\n",
    "# X_AE_train = mneFeatures(X_AE_train, dictListStacked[0]['fs'])\n",
    "# X_AE_test = mneFeatures(X_AE_test, dictListStacked[0]['fs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compress the geatures to the same latent size as the AE\n",
    "# pca = sklearn.decomposition.PCA(n_components=X_AE_train.shape[1])\n",
    "# # PCA data sets (train_test)\n",
    "# X_pca_train = pca.fit_transform(X_bench_train)\n",
    "# X_pca_test = pca.transform(X_bench_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of datasets\n",
    "print('Bench')\n",
    "print(X_bench_train.shape)\n",
    "print(X_bench_test.shape, '\\n')\n",
    "\n",
    "print('AE')\n",
    "print(X_AE_train.shape)\n",
    "print(X_AE_test.shape, '\\n')\n",
    "\n",
    "# print('PCA')\n",
    "# print(X_pca_train.shape)\n",
    "# print(X_pca_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b672ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbModel_bench = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "# lgbModel_pca = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "lgbModel_ae = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "\n",
    "# lgbModel_pca.fit(X_pca_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_bench = cross_val_score(lgbModel_bench, X_bench_train, y_train, cv=5)\n",
    "print('Bench-\\nIn day accuracy: ', np.mean(scores_bench))\n",
    "lgbModel_bench.fit(X_bench_train, y_train)\n",
    "print('Different day accuracy: ', lgbModel_bench.score(X_bench_test, y_test), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f7955",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(lgbModel_pca.score(X_pca_test, y_test))\n",
    "scores_ae = cross_val_score(lgbModel_ae, X_AE_train, y_train, cv=5)\n",
    "print('AE-\\nIn day accuracy: ', np.mean(scores_ae))\n",
    "lgbModel_ae.fit(X_AE_train, y_train)\n",
    "print('Different day accuracy: ', lgbModel_ae.score(X_AE_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d26a62",
   "metadata": {},
   "source": [
    "# Huge cell for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798907e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_days=[0,3]\n",
    "\n",
    "bench_diff_day_score = []\n",
    "bench_same_day_score = []\n",
    "\n",
    "AE_diff_day_score = []\n",
    "AE_same_day_score = []\n",
    "\n",
    "AE_list = []\n",
    "\n",
    "# Train Dataset\n",
    "signal_data = EEGDataSet_signal(dictListStacked, train_days)\n",
    "signal_data_loader = DataLoader(dataset=signal_data, batch_size=batch_sz, shuffle=True, num_workers=0)\n",
    "features_training_data = EEGDataSet(dictListStacked, train_days, test_flag=True)\n",
    "\n",
    "# Train model on training day\n",
    "day_zero_AE = convolution_AE(signal_data.n_channels, features_training_data.feat_mat, ae_learning_rt, filters_n=convolution_filters)\n",
    "trainer_1 = pl.Trainer(max_epochs=300, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "trainer_1.fit(day_zero_AE, train_dataloaders=signal_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a94f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop :)\n",
    "for i in range(train_days[1], len(dictListStacked)):\n",
    "    test_days = [i, i+1]\n",
    "    \n",
    "    # Create test Datasets\n",
    "    signal_test_data = EEGDataSet_signal(dictListStacked, test_days)\n",
    "    signal_test_data_loader = DataLoader(dataset=signal_test_data, batch_size=25, shuffle=True, num_workers=0)\n",
    "\n",
    "    feautres_test_data = EEGDataSet(dictListStacked, test_days, test_flag=True)\n",
    "    \n",
    "    # Add AE model perday\n",
    "    AE_list.append(convolution_AE(signal_data.n_channels, \\\n",
    "                                                  features_training_data.feat_mat,\\\n",
    "                                                  ae_learning_rt, filters_n=convolution_filters))\n",
    "    # Load weights of day 0 model\n",
    "    AE_list[i - train_days[1]].load_state_dict(day_zero_AE.state_dict())\n",
    "    AE_list[i - train_days[1]].kldm(True)\n",
    "    # Run model\n",
    "    # Create logger\n",
    "    logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "    # Create trainer\n",
    "    trainer_2 = pl.Trainer(max_epochs=150, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "    # Create netowrk model\n",
    "    # Train the model\n",
    "    trainer_2.fit(AE_list[i - train_days[1]], train_dataloaders=signal_test_data_loader)\n",
    "    \n",
    "    # Create features\n",
    "    # Bench\n",
    "    X_bench_train = features_training_data.feat_mat\n",
    "    y_train = features_training_data.y\n",
    "\n",
    "    X_bench_test = feautres_test_data.feat_mat\n",
    "    y_test = feautres_test_data.y\n",
    "    # AE\n",
    "    signal_train, _ = signal_data.getAllItems()\n",
    "    signal_test, _ = signal_test_data.getAllItems()\n",
    "#     # Use latent space as features\n",
    "#     X_AE_train = conv_AE_model.encode(signal_train).detach().numpy()\n",
    "#     X_AE_test = conv_AE_model.encode(signal_test).detach().numpy()\n",
    "\n",
    "#     X_AE_train = np.reshape(X_AE_train, (X_AE_train.shape[0], -1))\n",
    "#     X_AE_test = np.reshape(X_AE_test, (X_AE_test.shape[0], -1))\n",
    "\n",
    "    # Use recountructed signal to extract features from\n",
    "    rec_signal_train = AE_list[i-train_days[1]](signal_train).detach().numpy()\n",
    "    rec_signal_test = AE_list[i-train_days[1]](signal_test).detach().numpy()\n",
    "\n",
    "    X_AE_train = mneFeatures(rec_signal_train, dictListStacked[0]['fs'])\n",
    "    X_AE_test = mneFeatures(rec_signal_test, dictListStacked[0]['fs'])\n",
    "    \n",
    "    # Create lightgbm models\n",
    "    lgbModel_bench = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "    lgbModel_ae = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "    \n",
    "    # Fit lightGBM models\n",
    "    print('Day #',i)\n",
    "    scores_bench = cross_val_score(lgbModel_bench, X_AE_test, y_test, cv=8)\n",
    "    print('Bench-\\nIn day accuracy: ', np.mean(scores_bench))\n",
    "    lgbModel_bench.fit(X_bench_train, y_train)\n",
    "    bench_diff_day = lgbModel_bench.score(X_bench_test, y_test)\n",
    "    print('Different day accuracy: ',bench_diff_day , '\\n')\n",
    "    \n",
    "    scores_ae = cross_val_score(lgbModel_ae, X_AE_test, y_test, cv=8)\n",
    "    print('AE-\\nIn day accuracy: ', np.mean(scores_ae))\n",
    "    lgbModel_ae.fit(X_AE_train, y_train)\n",
    "    AE_diff_day = lgbModel_ae.score(X_AE_test, y_test)\n",
    "    print('Different day accuracy: ', AE_diff_day)\n",
    "    \n",
    "    AE_diff_day_score.append(AE_diff_day)\n",
    "    bench_diff_day_score.append(bench_diff_day) \n",
    "    AE_same_day_score.append(np.mean(scores_ae))\n",
    "    bench_same_day_score.append(np.mean(scores_bench))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606f49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(range(train_days[1], len(dictListStacked)), AE_diff_day_score, label='AE diff day', color='g')\n",
    "plt.plot(range(train_days[1], len(dictListStacked)), bench_diff_day_score, label='bench diff day', color='r')\n",
    "plt.axhline(y=np.mean(AE_diff_day_score), color='g', linestyle='--')\n",
    "plt.axhline(y=np.mean(bench_diff_day_score), color='r', linestyle='--')\n",
    "# plt.plot(range(train_days[1], len(dictListStacked)), bench_same_day_score[train_days[1]:], label='bench diff day', color='b')\n",
    "# plt.axhline(y=np.mean(bench_same_day_score[train_days[1]:]), color='b', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102e577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2269f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a3b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a6495f3",
   "metadata": {},
   "source": [
    "# Junk from here on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee986a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignal(elec, model, dataLoader):\n",
    "    # Create iterable object\n",
    "    data_iter = iter(dataLoader)\n",
    "    data, _ = data_iter.next()\n",
    "\n",
    "    \n",
    "    # Reconstruct data using given model\n",
    "    recon_data = model(data).detach()\n",
    "    \n",
    "    \n",
    "    # Plot original and reconstructed data\n",
    "    plt.figure(1)\n",
    "    plt.plot(data[0, elec, :], zorder=1)\n",
    "    plt.plot(recon_data[0, elec, :], zorder=0)\n",
    "    plt.legend(['Original', 'Reconstructed'])\n",
    "    plt.title(f'mse-Loss: {F.mse_loss(recon_data[0, elec, :], data[0, elec, :])}')\n",
    "    plt.xlabel('Time [mS]')\n",
    "    plt.ylabel('μV')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyICA(eegMat, eegInfo, excludeIdx, plotFlag=0):\n",
    "    eegRaw = mne.io.RawArray(eegMat, eegInfo)\n",
    "    ica = mne.preprocessing.ICA(n_components=11)\n",
    "    ica.fit(eegRaw)\n",
    "    ica.apply(eegRaw, exclude=excludeIdx)\n",
    "    \n",
    "    if plotFlag:\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(eegRaw)\n",
    "        plt.show()\n",
    "    eegMat = eegRaw.get_data()\n",
    "    return eegMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d02e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cspFeaturesExtract(signal, labels, eegInfo, cv_N = 5, plotFlag = 1):\n",
    "    \n",
    "    # Set verbose to 0\n",
    "    mne.set_log_level(verbose='WARNING', return_old_level=False, add_frames=None)\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "\n",
    "    # Assemble a classifier\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    csp = mne.decoding.CSP(n_components=16, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "    # Use scikit-learn Pipeline with cross_val_score function\n",
    "    clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "    scores = cross_val_score(clf, signal, labels, cv=cv_N, n_jobs=1)\n",
    "    # Printing the results\n",
    "    print(\"CSP mean accuracy: %f \" % (np.mean(scores)))\n",
    "    clf.fit(signal, labels)\n",
    "    \n",
    "    if plotFlag:\n",
    "        # plot CSP patterns estimated on full data for visualization\n",
    "        csp.fit_transform(signal, labels)\n",
    "        csp.plot_patterns(eegInfo, ch_type='eeg', units='Patterns (AU)', size=10)\n",
    "    \n",
    "    return np.mean(scores), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayZeroCompare(XZero, yZero, X, Xaligned, y,modelClass=LinearDiscriminantAnalysis(), eegInfo=None):\n",
    "        \n",
    "    if modelClass == 'CSP':\n",
    "        if eegInfo == None:\n",
    "            print('No eegInfo')\n",
    "        \n",
    "        zeroAcc, cspZero = cspFeaturesExtract(XZero, yZero, eegInfo, cv_N = 5, plotFlag = 0)\n",
    "        \n",
    "        diffAcc, _ = cspFeaturesExtract(X, y, eegInfo, cv_N = 5, plotFlag = 0)\n",
    "        \n",
    "        alignedPred = cspZero.predict(Xaligned)\n",
    "        alignedAcc = accuracy_score(y, alignedPred)\n",
    "\n",
    "        nonAlignedPred = cspZero.predict(X)\n",
    "        nonAlignedAcc = accuracy_score(y, nonAlignedPred)\n",
    "        return zeroAcc, diffAcc, alignedAcc, nonAlignedAcc\n",
    "\n",
    "        \n",
    "    modelZero = modelClass\n",
    "    zeroAcc = np.mean(cross_val_score(modelZero, XZero, yZero, cv=cv_N))\n",
    "    modelZero.fit(XZero, yZero)\n",
    "    \n",
    "    modelDiff = modelClass\n",
    "    diffAcc = np.mean(cross_val_score(modelDiff, X, y, cv=cv_N))\n",
    "    \n",
    "    alignedPred = modelZero.predict(Xaligned)\n",
    "    alignedAcc = accuracy_score(y, alignedPred)\n",
    "    \n",
    "    nonAlignedPred =  modelZero.predict(X)\n",
    "    nonAlignedAcc = accuracy_score(y, nonAlignedPred)\n",
    "    \n",
    "    return zeroAcc, diffAcc, alignedAcc, nonAlignedAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mneFeatures(X, fs):\n",
    "    selected_funcs = ['kurtosis', 'skewness', 'pow_freq_bands', 'spect_slope',\n",
    "                     'spect_entropy', 'spect_edge_freq', 'mean', 'variance', 'ptp_amp']\n",
    "#     params = {'pow_freq_bands__freq_bands' : np.array([[2,4],\n",
    "#                                                        [4,8],\n",
    "#                                                        [8, 10],\n",
    "#                                                        [10,12],\n",
    "#                                                        [12, 20],\n",
    "#                                                        [20, 25],\n",
    "#                                                        [25, 30]])}\n",
    "    params = {'pow_freq_bands__freq_bands' : np.arange(1,30)}\n",
    "    fe = FeatureExtractor(sfreq=fs, selected_funcs=selected_funcs, params=params)\n",
    "\n",
    "    X_features = fe.fit_transform(X)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpectro(eegDict, elec, nperseg=None):\n",
    "    SxxImagine = 0\n",
    "    SxxIdle = 0\n",
    "    print(eegDict['segmentedEEG'][1, elec].shape)\n",
    "    for idx, sample in enumerate(eegDict['segmentedEEG']):\n",
    "        _, _, SxxTemp = scipy.signal.spectrogram(sample[elec], dictListStacked[0]['fs'],\n",
    "                                            nperseg=nperseg, window='hann')\n",
    "        if eegDict['labels'][idx] == 1:\n",
    "            SxxImagine += SxxTemp\n",
    "        elif eegDict['labels'][idx] == 0:\n",
    "            SxxIdle += SxxTemp\n",
    "\n",
    "    f, t, _ = scipy.signal.spectrogram(sample[elec], dictListStacked[0]['fs'],\n",
    "                                        nperseg=nperseg)\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.pcolormesh(t, f, SxxImagine, shading='gouraud')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title('Imagine Trials Spectrogram \\n Channel ' + eegDict['chanLabels'][elec])\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.pcolormesh(t, f, SxxIdle, shading='gouraud')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.title('Idle Trials Spectrogram \\n Channel ' + eegDict['chanLabels'][elec])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create montage\n",
    "montage = createMontage(dictListStacked[0]['chanLabels'])\n",
    "eegInfo = mne.create_info(dictListStacked[0]['chanLabels'], dictListStacked[0]['fs'], ch_types='eeg')\n",
    "eegInfo.set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53337a07",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "#### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_N = 5\n",
    "ldaCV = np.zeros((1, len(dictListStacked)))\n",
    "rfCV = np.zeros((1, len(dictListStacked)))\n",
    "lgbCV = np.zeros((1, len(dictListStacked)))\n",
    "cspCV = np.zeros((1, len(dictListStacked)))\n",
    "\n",
    "for day_i in range(len(dictListStacked)):\n",
    "    print('\\nImagineTrials Ratio: ' ,np.sum(dictListStacked[day_i]['labels'] / dictListStacked[day_i]['trials_N']))\n",
    "    ldaCV[0, day_i], rfCV[0, day_i], lgbCV[0, day_i] = mneFeaturesCV(dictListStacked[day_i]['segmentedEEG'], dictListStacked[day_i]['labels'], \n",
    "                  dictListStacked[day_i]['fs'], cv_N=cv_N)\n",
    "    cspCV[0, day_i], _ = cspFeaturesExtract(dictListStacked[day_i]['segmentedEEG'], dictListStacked[day_i]['labels'],\n",
    "                                      eegInfo, cv_N=cv_N, plotFlag=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((ldaCV, rfCV, lgbCV, cspCV), axis=0)\n",
    "X = (np.arange(len(dictListStacked))) * 1.5\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_xticks(X)\n",
    "ax.set_yticks(np.arange(0,1,0.1))\n",
    "ax.set_xticklabels(range(1, len(dictListStacked) + 1))\n",
    "\n",
    "ax.bar(X - 0.25, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X + 0.00, data[1], color = 'g', width = 0.25)\n",
    "ax.bar(X + 0.25, data[2], color = 'r', width = 0.25)\n",
    "ax.bar(X + 0.50, data[3], color = 'y', width = 0.25)\n",
    "plt.legend(['lda', 'rf', 'lgb', 'csp'], loc=4)\n",
    "\n",
    "plt.axhline(y=np.mean(data[0]), color='b', linestyle='--')\n",
    "plt.axhline(y=np.mean(data[1]), color='g', linestyle='--')\n",
    "plt.axhline(y=np.mean(data[2]), color='r', linestyle='--')\n",
    "plt.axhline(y=np.mean(data[3]), color='y', linestyle='--')\n",
    "plt.axhline(y=0.5, color='k', linestyle='--')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb69f9f",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2fb5b",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet(Dataset):\n",
    "    def __init__(self, EEGmat, day=0):\n",
    "        # Data loading      \n",
    "        \n",
    "        \n",
    "        # INSERT PREPROCCESSING HERE #\n",
    "        # Make sure you end up with EEG and labels as follow:\n",
    "        # EEG --> [N_trials X N_channels X N_timestamps]\n",
    "        labels = np.squeeze(np.ones((1, EEGmat.shape[0])) * day)      \n",
    "        \n",
    "        \n",
    "        # Convert from numpy to tensor\n",
    "        self.x = torch.from_numpy(EEGmat)\n",
    "        self.y = torch.from_numpy(labels)\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.channels_N = self.x.shape[1]\n",
    "        self.timestamps = self.x.shape[2]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index].float() , self.y[index].float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def getAllItems(self):\n",
    "        return self.x.float() , self.y.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b80bd",
   "metadata": {},
   "source": [
    "### Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b009d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentedEEG = []\n",
    "# Extract and segment all the data\n",
    "for dayData in dataList:\n",
    "    # Extract each day data\n",
    "    interData = extractData(dayData)\n",
    "    # Filter the data\n",
    "    interData['EEG'] = eegFilters(interData['EEG'], interData['fs'], filterLim)\n",
    "    interData['EEG'] = interData['EEG'][(2,8),:]\n",
    "    # Segment the data\n",
    "    segmentedEEG.append(AEsegmentEEG(interData, trialLen=trialLen, edgesCut=4))\n",
    "\n",
    "# Stack matrix for each day \n",
    "EEGlist = []\n",
    "for i, mat_i in enumerate(segmentedEEG):\n",
    "    if i % len(block) == 0:\n",
    "        eegArray = mat_i\n",
    "    eegArray = np.concatenate((eegArray, mat_i))\n",
    "    if i % len(block) == len(block) - 1:\n",
    "        EEGlist.append(eegArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day Zero\n",
    "dayZeroDataSet = EEGDataSet(EEGlist[0], day=0)\n",
    "dayZeroDataLoader = DataLoader(dataset=dayZeroDataSet, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "print(len(dayZeroDataSet))\n",
    "print(dayZeroDataSet.timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62fbb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(max_epochs=100, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "# Create netowrk model\n",
    "AEmodel = lightAE(dayZeroDataSet.channels_N, 1, 3e-4)\n",
    "# Train the model\n",
    "trainer.fit(AEmodel, train_dataloaders=dayZeroDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data reduction:')\n",
    "print('Original-',torch.unsqueeze(dayZeroDataSet[0][0],0).shape)\n",
    "a = AEmodel.encode(torch.unsqueeze(dayZeroDataSet[0][0],0))\n",
    "print('Compacted-',a.shape)\n",
    "print('Ratio - ', np.dot(a.shape[1], a.shape[2]) / np.dot(dayZeroDataSet[0][0].shape[0],dayZeroDataSet[0][0].shape[1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908a776",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotSignal(elec=0, model=AEmodel, dataLoader=dayZeroDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysPlots = [0,1,2,3,4,5,6,7]\n",
    "diffDayIdx = 4\n",
    "distType = 'norm'\n",
    "\n",
    "pdfList = plotResDist(EEGlist, AEmodel, daysPlots, plotType='stacked', distType=distType)\n",
    "print(f'Wasserstein distance between days 0 and {diffDayIdx}- {wasserstein_distance(pdfList[0], pdfList[diffDayIdx])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResDist(EEGlist, AEmodel, daysPlots, plotType='hist', distType=distType)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456076d6",
   "metadata": {},
   "source": [
    "# Align data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c643ca6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alignerList = []\n",
    "dayZeroDat = dayZeroDataSet.getAllItems()[0]\n",
    "l1Res = AEmodel.getResNorm(dayZeroDat)\n",
    "\n",
    "for dayIdx in range(1 ,len(EEGlist)):\n",
    "    # Each day data loader\n",
    "    diffDayDataSet = EEGDataSet(EEGlist[dayIdx], day=dayIdx)\n",
    "    diffDayDataLoader = DataLoader(dataset=diffDayDataSet, batch_size=int(1 * len(diffDayDataSet)), shuffle=True, num_workers=0)\n",
    "    # Create logger\n",
    "    logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "    # Create trainer\n",
    "    trainer = pl.Trainer(max_epochs=150, gpus=0, progress_bar_refresh_rate=1, logger=logger)\n",
    "    # Create netowrk model\n",
    "    aligner = alignerModel(diffDayDataSet.channels_N, diffDayDataSet.timestamps ,l1Res, AEmodel=AEmodel,\n",
    "                           varFactor=3e-4, learning_rate=3e-4)\n",
    "    # Train the model\n",
    "    aligner.train()\n",
    "    trainer.fit(aligner, train_dataloaders=diffDayDataLoader)\n",
    "    aligner.eval()\n",
    "    alignerList.append(aligner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb378dd5",
   "metadata": {},
   "source": [
    "### Using MNE-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayZeroAccList = []\n",
    "diffDayAccList = []\n",
    "alignedDayAccList = []\n",
    "nonAlignedAccList = []\n",
    "\n",
    "modelType = LinearDiscriminantAnalysis()\n",
    "# modelType = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "# modelType = RandomForestClassifier()\n",
    "\n",
    "# Day Zero data arrangment\n",
    "XZero = dictListStacked[0]['segmentedEEG']\n",
    "XZero = mneFeatures(XZero, dictListStacked[0]['fs'])\n",
    "yZero = dictListStacked[0]['labels']\n",
    "\n",
    "# Other days data arrangment\n",
    "for dayIdx in range(1 ,len(EEGlist)):\n",
    "    # Allign the data\n",
    "    X = dictListStacked[dayIdx]['segmentedEEG']\n",
    "    Xaligned = alignerList[dayIdx - 1](torch.Tensor(X)).detach().numpy()\n",
    "    # mne Features exrtaction\n",
    "    X = mneFeatures(X, dictListStacked[0]['fs'])\n",
    "    Xaligned = mneFeatures(Xaligned, dictListStacked[0]['fs'])\n",
    "    # Labels\n",
    "    y = dictListStacked[dayIdx]['labels']\n",
    "    zeroAcc, diffAcc, alignedAcc, nonAlignedAcc = dayZeroCompare(XZero, yZero, X, Xaligned, y, modelType, eegInfo=eegInfo)\n",
    "    dayZeroAccList.append(zeroAcc)\n",
    "    diffDayAccList.append(diffAcc)\n",
    "    alignedDayAccList.append(alignedAcc)\n",
    "    nonAlignedAccList.append(nonAlignedAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f86594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotDaysAcc(diffDayAccList, alignedDayAccList, nonAlignedAccList, zeroAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f570845",
   "metadata": {},
   "source": [
    "### Using CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayZeroAccList = []\n",
    "diffDayAccList = []\n",
    "alignedDayAccList = []\n",
    "nonAlignedAccList = []\n",
    "\n",
    "modelType = 'CSP'\n",
    "\n",
    "# Day Zero data arrangment\n",
    "XZero = dictListStacked[0]['segmentedEEG']\n",
    "yZero = dictListStacked[0]['labels']\n",
    "\n",
    "# Other days data arrangment\n",
    "for dayIdx in range(1 ,len(EEGlist)):\n",
    "    # Allign the data\n",
    "    X = dictListStacked[dayIdx]['segmentedEEG']\n",
    "    Xaligned = alignerList[dayIdx - 1](torch.Tensor(X)).detach().numpy()\n",
    "    # Labels\n",
    "    y = dictListStacked[dayIdx]['labels']\n",
    "    zeroAcc, diffAcc, alignedAcc, nonAlignedAcc = dayZeroCompare(XZero, yZero, X, Xaligned, y, modelType, eegInfo=eegInfo)\n",
    "    dayZeroAccList.append(zeroAcc)\n",
    "    diffDayAccList.append(diffAcc)\n",
    "    alignedDayAccList.append(alignedAcc)\n",
    "    nonAlignedAccList.append(nonAlignedAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49817f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDaysAcc(diffDayAccList, alignedDayAccList, nonAlignedAccList, zeroAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79366ea",
   "metadata": {},
   "source": [
    "### Using Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayZeroAccList = []\n",
    "diffDayAccList = []\n",
    "alignedDayAccList = []\n",
    "nonAlignedAccList = []\n",
    "\n",
    "# modelType = LinearDiscriminantAnalysis()\n",
    "# modelType = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5)\n",
    "modelType = RandomForestClassifier()\n",
    "\n",
    "# Day Zero data arrangment\n",
    "XZero = dictListStacked[0]['segmentedEEG']\n",
    "XZero = AEmodel.encode(torch.Tensor(XZero)).detach().numpy()\n",
    "XZero = np.reshape(XZero, (XZero.shape[0], XZero.shape[1] * XZero.shape[2]))\n",
    "yZero = dictListStacked[0]['labels']\n",
    "\n",
    "# Other days data arrangment\n",
    "for dayIdx in range(1 ,len(EEGlist)):\n",
    "    # Allign the data\n",
    "    X = dictListStacked[dayIdx]['segmentedEEG']\n",
    "    Xaligned = alignerList[dayIdx - 1](torch.Tensor(X)).detach().numpy()\n",
    "    # latent Features exrtaction\n",
    "    X = AEmodel.encode(torch.Tensor(X)).detach().numpy()\n",
    "    Xaligned = AEmodel.encode(torch.Tensor(Xaligned)).detach().numpy()\n",
    "    # Flatten the features\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2]))\n",
    "    Xaligned = np.reshape(Xaligned, (Xaligned.shape[0], Xaligned.shape[1] * Xaligned.shape[2]))\n",
    "    # Labels\n",
    "    y = dictListStacked[dayIdx]['labels']\n",
    "    zeroAcc, diffAcc, alignedAcc, nonAlignedAcc = dayZeroCompare(XZero, yZero, X, Xaligned, y, modelType, eegInfo=eegInfo)\n",
    "    dayZeroAccList.append(zeroAcc)\n",
    "    diffDayAccList.append(diffAcc)\n",
    "    alignedDayAccList.append(alignedAcc)\n",
    "    nonAlignedAccList.append(nonAlignedAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDaysAcc(diffDayAccList, alignedDayAccList, nonAlignedAccList, zeroAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ad25c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e945080",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dayPlot = 4\n",
    "plotAlignerDist(EEGlist, AEmodel, alignerList[dayPlot], dayPlot, distType=distType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAlignedEEG(diffDayDataSet, alignerList[dayPlot - 1], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535168c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(alignerList[dayPlot].fc1.weight.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
