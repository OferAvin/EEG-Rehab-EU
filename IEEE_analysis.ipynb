{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io\n",
    "import mne\n",
    "import sklearn\n",
    "import os \n",
    "import random\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from itertools import chain, product\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from scipy.stats import norm, wasserstein_distance\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa436bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Utility functions frmo diffrent notebooks\n",
    "import import_ipynb\n",
    "from IEEE_data import extract_ieee_data, LazyProperty, data_4class\n",
    "from CHIST_ERA_data import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mneFeatures(X, fs):\n",
    "    selected_funcs = ['line_length', 'kurtosis', 'skewness', 'pow_freq_bands', 'spect_slope',\n",
    "                     'spect_entropy', 'spect_edge_freq', 'mean', 'variance', 'ptp_amp']\n",
    "    params = {'pow_freq_bands__freq_bands' : np.array([[8, 10],\n",
    "                                                      [10,12],\n",
    "                                                      [9, 13],\n",
    "                                                      [12, 20],\n",
    "                                                      [20, 25],\n",
    "                                                      [25, 30]])}\n",
    "    fe = FeatureExtractor(sfreq=fs, selected_funcs=selected_funcs, params=params)\n",
    "\n",
    "    X_features = fe.fit_transform(X)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csp_score(signal, labels, cv_N = 5, classifier = False):\n",
    "    \n",
    "    # Set verbose to 0\n",
    "    mne.set_log_level(verbose='WARNING', return_old_level=False, add_frames=None)\n",
    "\n",
    "    # Define a monte-carlo cross-validation generator (reduce variance):\n",
    "    scores = []\n",
    "    \n",
    "    if classifier:\n",
    "        y_pred = classifier.predict(signal)\n",
    "        acc = sklearn.metrics.accuracy_score(labels, y_pred)\n",
    "        return acc\n",
    "    \n",
    "    else:\n",
    "        # Assemble a classifier\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "#         lda = sklearn.ensemble.RandomForestClassifier()\n",
    "        csp = mne.decoding.CSP(n_components=26, reg=None, log=False, norm_trace=True)\n",
    "        # Use scikit-learn Pipeline with cross_val_score function\n",
    "        clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "        scores = cross_val_score(clf, signal, labels, cv=cv_N, n_jobs=1)\n",
    "        clf.fit(signal, labels)\n",
    "        return np.mean(scores), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5039a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mneFeatures(X, fs):\n",
    "    selected_funcs = ['line_length', 'kurtosis', 'skewness', 'pow_freq_bands']\n",
    "    params = {'pow_freq_bands__freq_bands' : np.array([[8, 10],\n",
    "                                                      [10,12],\n",
    "                                                      [9, 13],\n",
    "                                                      [12, 20],\n",
    "                                                      [20, 25],\n",
    "                                                      [25, 30]])}\n",
    "    fe = FeatureExtractor(sfreq=fs, selected_funcs=selected_funcs, params=params)\n",
    "\n",
    "    X_features = fe.fit_transform(X)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aed0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mne_classifier(signal, labels, fs, zero_time, classifier = False):\n",
    "    # cut signal before + after\n",
    "    signal_before = signal[:, :, :fs*zero_time]\n",
    "    signal_after = signal[:, :, fs*zero_time:]\n",
    "    # Get features\n",
    "    features_before = mneFeatures(signal_before, fs)\n",
    "    features_after = mneFeatures(signal_after, fs)\n",
    "    \n",
    "#     X = np.hstack((features_before, features_after))\n",
    "    X = np.divide(features_before, features_after)\n",
    "    if classifier:\n",
    "        score = features_classfier(X, labels, 5, classifier)\n",
    "        return score\n",
    "    else:\n",
    "        score, clf = features_classfier(X, labels, 5, classifier)\n",
    "    return score, clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_classfier(X, y, cv_N = 5, classifier = False):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    if classifier:\n",
    "        y_pred = classifier.predict(X)\n",
    "        acc = sklearn.metrics.accuracy_score(y, y_pred)\n",
    "        return acc\n",
    "    \n",
    "    else:\n",
    "        # Assemble a classifier\n",
    "#         clf = RandomForestClassifier()\n",
    "        clf = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\n",
    "        scores = cross_val_score(clf, X, y, cv=cv_N, n_jobs=1)\n",
    "        clf.fit(X, y)\n",
    "        return np.mean(scores), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_annotate_brackets(num1, num2, data, center, height, yerr=None, dh=.05, barh=.05, fs=None, maxasterix=None):\n",
    "    \"\"\" \n",
    "    Annotate barplot with p-values.\n",
    "\n",
    "    :param num1: number of left bar to put bracket over\n",
    "    :param num2: number of right bar to put bracket over\n",
    "    :param data: string to write or number for generating asterixes\n",
    "    :param center: centers of all bars (like plt.bar() input)\n",
    "    :param height: heights of all bars (like plt.bar() input)\n",
    "    :param yerr: yerrs of all bars (like plt.bar() input)\n",
    "    :param dh: height offset over bar / bar + yerr in axes coordinates (0 to 1)\n",
    "    :param barh: bar height in axes coordinates (0 to 1)\n",
    "    :param fs: font size\n",
    "    :param maxasterix: maximum number of asterixes to write (for very small p-values)\n",
    "    \"\"\"\n",
    "\n",
    "    if type(data) is str:\n",
    "        text = data\n",
    "    else:\n",
    "        # * is p < 0.05\n",
    "        # ** is p < 0.005\n",
    "        # *** is p < 0.0005\n",
    "        # etc.\n",
    "        text = ''\n",
    "        p = .05\n",
    "\n",
    "        while data < p:\n",
    "            text += '*'\n",
    "            p /= 10.\n",
    "\n",
    "            if maxasterix and len(text) == maxasterix:\n",
    "                break\n",
    "\n",
    "        if len(text) == 0:\n",
    "            text = 'n. s.'\n",
    "\n",
    "    lx, ly = center[num1], height[num1]\n",
    "    rx, ry = center[num2], height[num2]\n",
    "\n",
    "    ly += yerr[num1]\n",
    "    ry += yerr[num2]\n",
    "\n",
    "    ax_y0, ax_y1 = plt.gca().get_ylim()\n",
    "    dh *= (ax_y1 - ax_y0)\n",
    "    barh *= (ax_y1 - ax_y0)\n",
    "\n",
    "    y = max(ly, ry) + dh\n",
    "\n",
    "    barx = [lx, lx, rx, rx]\n",
    "    bary = [y, y+barh, y+barh, y]\n",
    "    mid = ((lx+rx)/2, y+barh+0.05)\n",
    "\n",
    "    plt.plot(barx, bary, c='black')\n",
    "\n",
    "    kwargs = dict(ha='center', va='bottom')\n",
    "    if fs is not None:\n",
    "        kwargs['fontsize'] = fs\n",
    "\n",
    "    plt.text(*mid, text, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_day_classifier(eeg_list):\n",
    "    # Use day zero classifier for classifying the reconstructed eeg per day\n",
    "    \n",
    "    residuals = []\n",
    "    labels = []\n",
    "    for day_i in range(len(eeg_list)):\n",
    "        # Get data\n",
    "        signal_test_data = EEGDataSet_signal(dictListStacked, [day_i, day_i+1])\n",
    "        signal_test, y_test = signal_test_data.getAllItems()\n",
    "       \n",
    "        # Get residuals\n",
    "        residuals.append(signal_test.detach().numpy())\n",
    "        labels.append(np.ones((1, signal_test.shape[0])) * day_i)\n",
    "    labels= np.hstack(labels)\n",
    "    labels = np.squeeze(labels)\n",
    "    residuals = np.vstack(residuals)\n",
    "\n",
    "    score, _ = csp_score(np.float64(residuals), labels, cv_N = 5, classifier = False)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_day_classifier(AE_model, eeg_list):\n",
    "    # Use day zero classifier for classifying the reconstructed eeg per day\n",
    "    \n",
    "    residuals = []\n",
    "    labels = []\n",
    "    for day_i in range(len(eeg_list)):\n",
    "        # Get data\n",
    "        signal_test_data = EEGDataSet_signal(dictListStacked, [day_i, day_i+1])\n",
    "        signal_test, y_test = signal_test_data.getAllItems()\n",
    "\n",
    "        # reconstruct EEG AE\n",
    "        rec_signal = AE_model(signal_test).detach().numpy()        \n",
    "        # Get residuals\n",
    "        residuals.append(rec_signal)\n",
    "        labels.append(np.ones((1, signal_test.shape[0])) * day_i)\n",
    "    labels= np.hstack(labels)\n",
    "    labels = np.squeeze(labels)\n",
    "    residuals = np.vstack(residuals)\n",
    "\n",
    "    score, _ = csp_score(np.float64(residuals), labels, cv_N = 5, classifier = False)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_day_classifier(AE_model, eeg_list):\n",
    "    # Use day zero classifier for classifying the residuals per day\n",
    "    \n",
    "    residuals = []\n",
    "    labels = []\n",
    "    for day_i in range(len(eeg_list)):\n",
    "        # Get data\n",
    "        signal_test_data = EEGDataSet_signal(dictListStacked, [day_i, day_i+1])\n",
    "        signal_test, y_test = signal_test_data.getAllItems()\n",
    "\n",
    "        # reconstruct EEG AE\n",
    "        rec_signal = AE_model(signal_test).detach().numpy()        \n",
    "        # Get residuals\n",
    "        residuals.append((signal_test - rec_signal).detach().numpy())\n",
    "        labels.append(np.ones((1, signal_test.shape[0])) * day_i)\n",
    "    labels= np.hstack(labels)\n",
    "    labels = np.squeeze(labels)\n",
    "    residuals = np.vstack(residuals)\n",
    "\n",
    "    score, _ = csp_score(np.float64(residuals), labels, cv_N = 5, classifier = False)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77144ecd",
   "metadata": {},
   "source": [
    "### Datset and Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecefb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet_signal(Dataset):\n",
    "    def __init__(self, EEGDict, days_range=[0,1]):\n",
    "        \n",
    "        # Concat dict      \n",
    "        X, y = self.concat(EEGDict, days_range)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Convert from numpy to tensor\n",
    "        self.X = torch.tensor(X)\n",
    "        self.n_samples = self.X.shape[0]\n",
    "        self.n_channels = self.X.shape[1]\n",
    "        self.y = y\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index].float(), self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def getAllItems(self):\n",
    "        return self.X.float() , self.y\n",
    "    \n",
    "    def concat(self, EEGDict, days_range):\n",
    "        X = []\n",
    "        y = []\n",
    "        for d in dictListStacked[days_range[0]:days_range[1]]:\n",
    "            X.append(d['segmentedEEG'])\n",
    "            y.append(d['labels'])\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        X = np.concatenate(X)\n",
    "        y = np.concatenate(y)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution_AE(LightningModule):\n",
    "    def __init__(self, input_channels, learning_rate=1e-3, filters_n = [16, 32, 64], pca_W = False):\n",
    "        super().__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.filters_n = filters_n\n",
    "        self.learning_rate = learning_rate\n",
    "        self.float()\n",
    "        self.l1_filters, self.l2_filters, self.l3_filters = self.filters_n\n",
    "\n",
    "        self.pca_W = pca_W\n",
    "        ### The model architecture ###\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Conv1d(self.input_channels, self.l1_filters, kernel_size=15, stride=2, padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv1d(self.l1_filters, self.l2_filters, kernel_size=10, stride=2, padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv1d(self.l2_filters, self.l3_filters, kernel_size=5, stride=2, padding=1),\n",
    "        nn.LeakyReLU()\n",
    "        )\n",
    "                \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "        # IMPORTENT - on the IEEE dataset - the output padding needs to be 1 in the row below -on CHIST-ERA its 1\n",
    "        nn.ConvTranspose1d(self.l3_filters, self.l2_filters, kernel_size=5, stride=2, padding=1, output_padding=1),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.ConvTranspose1d(self.l2_filters, self.l1_filters, kernel_size=10, stride=2, padding=1, output_padding=0),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.ConvTranspose1d(self.l1_filters, self.input_channels, kernel_size=15, stride=2, padding=1, output_padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # Forward through the layeres\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # Recountruction\n",
    "        logits = self.forward(x)\n",
    "        # Loss function\n",
    "        try:\n",
    "            if len(self.pca_W.shape)>0:\n",
    "                rec_error = pca_error(self.pca_W, logits)\n",
    "                loss = F.mse_loss(logits, x) + 0*rec_error\n",
    "        except:\n",
    "            loss = F.mse_loss(logits, x)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d26a62",
   "metadata": {},
   "source": [
    "# Training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_days, dictListStacked, fs, ae_learning_rt, convolution_filters, batch_sz, zero_time, epoch_n):\n",
    "    \n",
    "\n",
    "    # Logger\n",
    "    logger = TensorBoardLogger('tb_logs', name='EEG_Logger')\n",
    "\n",
    "    # Train Dataset\n",
    "    signal_data = EEGDataSet_signal(dictListStacked, train_days)\n",
    "    signal_data_loader = DataLoader(dataset=signal_data, batch_size=batch_sz, shuffle=True, num_workers=0)\n",
    "    x, y = signal_data.getAllItems()\n",
    "\n",
    "    # Train model on training day\n",
    "    day_zero_AE = convolution_AE(signal_data.n_channels, ae_learning_rt, filters_n=convolution_filters)\n",
    "    trainer_1 = pl.Trainer(max_epochs=epoch_n, gpus=0, progress_bar_refresh_rate=20, logger=logger)\n",
    "    trainer_1.fit(day_zero_AE, train_dataloaders=signal_data_loader)\n",
    "    \n",
    "    # Day 0 classifier\n",
    "#     score_ae, day_zero_AE_clf = mne_classifier(day_zero_AE(x).detach().numpy(), y, fs, zero_time, classifier = False)\n",
    "#     score_bench, day_zero_bench_clf = mne_classifier(x.detach().numpy(), y, fs, zero_time, classifier = False)\n",
    "    score_ae, day_zero_AE_clf = csp_score(np.float64(day_zero_AE(x).detach().numpy()), y, cv_N = 5, classifier = False)\n",
    "    score_bench, day_zero_bench_clf = csp_score(np.float64(x.detach().numpy()), y, cv_N = 5, classifier = False)\n",
    "\n",
    "    # Loop :)\n",
    "    bench_diff_day_score = []\n",
    "    bench_same_day_score = []\n",
    "    AE_diff_day_score = []\n",
    "    \n",
    "    # Append day zero score\n",
    "    bench_diff_day_score.append(score_bench)\n",
    "    bench_same_day_score.append(score_bench)\n",
    "    AE_diff_day_score.append(score_ae)\n",
    "\n",
    "    for i in range(train_days[1], len(dictListStacked)):\n",
    "        test_days = [i, i+1]\n",
    "\n",
    "        # Create test Datasets\n",
    "        signal_test_data = EEGDataSet_signal(dictListStacked, test_days)\n",
    "        signal_test_data_loader = DataLoader(dataset=signal_test_data, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "        # get data\n",
    "        signal_test, y_test = signal_test_data.getAllItems()\n",
    "        # reconstruct EEG using day 0 AE\n",
    "        rec_signal_zero = day_zero_AE(signal_test).detach().numpy()\n",
    "\n",
    "\n",
    "        # Use models\n",
    "        print('Day #',i)\n",
    "        same_day_score, _ = csp_score(np.float64(signal_test.detach().numpy()), y_test, cv_N = 5, classifier = False)\n",
    "#         same_day_score, _ = mne_classifier(signal_test.detach().numpy(), y_test, fs, zero_time, classifier = False)\n",
    "        print('Bench-\\nIn day accuracy: ', same_day_score)\n",
    "        bench_diff_day = csp_score(np.float64(signal_test.detach().numpy()), y_test, cv_N = 5, classifier = day_zero_bench_clf)\n",
    "#         bench_diff_day  = mne_classifier(signal_test.detach().numpy(), y_test, fs, zero_time, day_zero_bench_clf)\n",
    "        print('Different day accuracy: ',bench_diff_day)\n",
    "\n",
    "        AE_diff_day = csp_score(rec_signal_zero, y_test, cv_N = 5, classifier = day_zero_AE_clf)\n",
    "#         AE_diff_day =  mne_classifier(rec_signal_zero, y_test, fs, zero_time, day_zero_AE_clf)\n",
    "        print('AE-\\nDifferent day accuracy: ', AE_diff_day, '\\n')\n",
    "\n",
    "        # Append each day results\n",
    "        AE_diff_day_score.append(AE_diff_day)\n",
    "        bench_diff_day_score.append(bench_diff_day) \n",
    "        bench_same_day_score.append(same_day_score)\n",
    "    \n",
    "    return bench_same_day_score, bench_diff_day_score, AE_diff_day_score, day_zero_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2af1c",
   "metadata": {},
   "source": [
    "### Load the files - IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a19185",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0\n",
    "tmax = 6\n",
    "select_label = [1,4]\n",
    "zero_time = 0\n",
    "\n",
    "filterLim = [8,30] # In Hz\n",
    "batch_sz = 16\n",
    "fs = 500\n",
    "ae_learning_rt = 1e-3\n",
    "n_epochs = 250\n",
    "batch_sz = 16\n",
    "convolution_filters = [8,16,32]\n",
    "\n",
    "amp_thresh = 250\n",
    "min_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe1588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = 'S6'\n",
    "dictListStacked = extract_ieee_data(sub, filterLim, tmin, tmax, select_label, data_dir = 'data/ieee_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove noisy trials using amplitude threshold\n",
    "new_dict_list = []\n",
    "for i, D in enumerate(dictListStacked):\n",
    "    max_amp = np.amax(np.amax(D['segmentedEEG'], 2), 1)\n",
    "    min_amp = np.amin(np.amin(D['segmentedEEG'], 2), 1)\n",
    "    max_tr = max_amp > amp_thresh \n",
    "    min_tr = min_amp < -amp_thresh\n",
    "    noisy_trials = [a or b for a, b in zip(max_tr, min_tr)]\n",
    "    D['segmentedEEG'] = np.delete(D['segmentedEEG'], noisy_trials,axis=0)\n",
    "    D['labels'] = np.delete(D['labels'], noisy_trials,axis=0)\n",
    "    if D['segmentedEEG'].shape[0] > min_trials:\n",
    "            new_dict_list.append(D)\n",
    "\n",
    "dictListStacked = new_dict_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec05ac1",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub 206 - 200 epochs\n",
    "train_days=[0,1]\n",
    "\n",
    "bench_same_day_score, bench_diff_day_score, AE_diff_day_score, _ = \\\n",
    "training_loop(train_days, dictListStacked, fs, ae_learning_rt, convolution_filters, batch_sz, zero_time, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from which day to plot?\n",
    "plot_from = 0\n",
    "\n",
    "# Plot\n",
    "plt.plot(range(plot_from, plot_from + len(AE_diff_day_score[plot_from:])), AE_diff_day_score[plot_from:], label='AE diff day', color='g')\n",
    "plt.plot(range(plot_from, plot_from + len(AE_diff_day_score[plot_from:])), bench_diff_day_score[plot_from:], label='bench diff day', color='r')\n",
    "plt.plot(range(plot_from, plot_from + len(AE_diff_day_score[plot_from:])), bench_same_day_score[plot_from:], label='bench same day', color='b')\n",
    "\n",
    "plt.axhline(y=np.mean(AE_diff_day_score[plot_from:]), color='g', linestyle='--')\n",
    "plt.axhline(y=np.mean(bench_diff_day_score[plot_from:]), color='r', linestyle='--')\n",
    "plt.axhline(y=np.mean(bench_same_day_score[plot_from:]), color='b', linestyle='--')\n",
    "\n",
    "plt.title('Accuracy Over Days - Using Day 0 Classifier')\n",
    "plt.xlabel('Day #')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06adb2",
   "metadata": {},
   "source": [
    "# Loop over all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd55ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corrupted files - A1, A4(maybe?), A5(maybe?), A8(maybe?), S1(maybe?), S4(maybe?)\n",
    "sub_list = ['A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8',\n",
    "           'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8','S9','S10','S11', 'S12']\n",
    "\n",
    "same_list = []\n",
    "diff_list = []\n",
    "AE_list = []\n",
    "day_classification_score = []\n",
    "for sub in sub_list:\n",
    "    dictListStacked = extract_ieee_data(sub, filterLim, tmin, tmax, select_label, data_dir = 'data/ieee_dataset/')\n",
    "    \n",
    "    # Remove noisy trials using amplitude threshold\n",
    "    new_dict_list = []\n",
    "    for i, D in enumerate(dictListStacked):\n",
    "        max_amp = np.amax(np.amax(D['segmentedEEG'], 2), 1)\n",
    "        min_amp = np.amin(np.amin(D['segmentedEEG'], 2), 1)\n",
    "        max_tr = max_amp > amp_thresh \n",
    "        min_tr = min_amp < -amp_thresh\n",
    "        noisy_trials = [a or b for a, b in zip(max_tr, min_tr)]\n",
    "        D['segmentedEEG'] = np.delete(D['segmentedEEG'], noisy_trials,axis=0)\n",
    "        D['labels'] = np.delete(D['labels'], noisy_trials,axis=0)\n",
    "        if D['segmentedEEG'].shape[0] > min_trials:\n",
    "                new_dict_list.append(D)\n",
    "\n",
    "    dictListStacked = new_dict_list\n",
    "        \n",
    "    train_days=[0,1]\n",
    "    \n",
    "    bench_same_day_score, bench_diff_day_score, AE_diff_day_score, day_zero_AE = \\\n",
    "    training_loop(train_days, dictListStacked, fs, ae_learning_rt, convolution_filters, batch_sz, zero_time, n_epochs)\n",
    "    \n",
    "    # Day classfication using residuals original and recontrusted EEG\n",
    "    res_score = residual_day_classifier(day_zero_AE, dictListStacked)\n",
    "    rec_score = reconstruction_day_classifier(day_zero_AE, dictListStacked)\n",
    "    orig_score = original_day_classifier(dictListStacked)\n",
    "    day_classification_score.append([orig_score, rec_score, res_score])\n",
    "    \n",
    "    # Add results\n",
    "    same_list.append(bench_same_day_score)\n",
    "    diff_list.append(bench_diff_day_score)\n",
    "    AE_list.append(AE_diff_day_score)\n",
    "    print(sub)\n",
    "    print(np.mean(bench_same_day_score))\n",
    "    print(np.mean(bench_diff_day_score))\n",
    "    print(np.mean(AE_diff_day_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_same = []\n",
    "ok_diff = []\n",
    "ok_AE = []\n",
    "\n",
    "for i in range(len(diff_list)):\n",
    "    if np.mean(same_list[i]) > 0.65:\n",
    "        \n",
    "        if len(same_list[i]) < 7:\n",
    "            continue\n",
    "        ok_same.append(np.asarray(same_list[i][:]))\n",
    "        ok_diff.append(np.asarray(diff_list[i][:]))\n",
    "        ok_AE.append(np.asarray(AE_list[i][:]))\n",
    "\n",
    "sub_N = len(ok_same)        \n",
    "ok_same = np.mean(np.vstack(ok_same), axis = 0)\n",
    "ok_diff = np.mean(np.vstack(ok_diff), axis = 0)\n",
    "ok_AE = np.mean(np.vstack(ok_AE), axis = 0)\n",
    "\n",
    "\n",
    "# Start from which day to plot?\n",
    "plot_from = 0\n",
    "\n",
    "# Plot\n",
    "plt.plot(range(plot_from, plot_from + len(ok_diff[plot_from:])), ok_AE[plot_from:], label='AE diff day', color='g')\n",
    "plt.plot(range(plot_from, plot_from + len(ok_diff[plot_from:])), ok_diff[plot_from:], label='bench diff day', color='r')\n",
    "plt.plot(range(plot_from, plot_from + len(ok_diff[plot_from:])), ok_same[plot_from:], label='bench same day', color='b')\n",
    "\n",
    "plt.axhline(y=np.mean(ok_AE[plot_from:]), color='g', linestyle='--')\n",
    "plt.axhline(y=np.mean(ok_diff[plot_from:]), color='r', linestyle='--')\n",
    "plt.axhline(y=np.mean(ok_same[plot_from:]), color='b', linestyle='--')\n",
    "\n",
    "plt.title(f'Accuracy Over Days - Using Day 0 Classifier\\nMean over {sub_N} Subjects')\n",
    "plt.xlabel('Day #')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p_01 = scipy.stats.ttest_ind(np.vstack(day_classification_score)[:,1],np.vstack(day_classification_score)[:,0])\n",
    "_, p_12 = scipy.stats.ttest_ind(np.vstack(day_classification_score)[:,1],np.vstack(day_classification_score)[:,2])\n",
    "_, p_02 = scipy.stats.ttest_ind(np.vstack(day_classification_score)[:,2],np.vstack(day_classification_score)[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8841eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = days_classification_mean\n",
    "bars = np.arange(len(heights))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(bars, heights, align='center', yerr=days_classification_std)\n",
    "plt.ylim(0, 1.5)\n",
    "barplot_annotate_brackets(0, 1, f'p = {np.round(p_01,decimals=6)}', bars, heights, yerr=days_classification_std)\n",
    "barplot_annotate_brackets(1, 2, f'p = {np.round(p_12,decimals=6)}', bars, heights, yerr=days_classification_std)\n",
    "barplot_annotate_brackets(0, 2, f'p = {np.round(p_02,decimals=6)}', bars, heights, dh=.2, yerr=days_classification_std)\n",
    "plt.xticks(ticks=bars, labels=['Original', 'Recontructed', 'Residuals'])\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "plt.title('Accuracy of Signal Origin Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3b957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_classification_mean = np.mean(np.vstack(day_classification_score), axis = 0)\n",
    "days_classification_std = np.std(np.vstack(day_classification_score), axis = 0)\n",
    "plt.figure()\n",
    "\n",
    "plt.bar([2,4,6], days_classification_mean, width=0.8, align='center', tick_label=['Original', 'Recontructed', 'Residuals'],\\\n",
    "    yerr=days_classification_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a42ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56840ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(diff_list)):\n",
    "    plt.figure(i)\n",
    "    # Start from which day to plot?\n",
    "    plot_from = 0\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), AE_list[i][plot_from:], label='AE diff day', color='g')\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), diff_list[i][plot_from:], label='bench diff day', color='r')\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), same_list[i][plot_from:], label='bench same day', color='b')\n",
    "\n",
    "    plt.axhline(y=np.mean(AE_list[i][plot_from:]), color='g', linestyle='--')\n",
    "    plt.axhline(y=np.mean(diff_list[i][plot_from:]), color='r', linestyle='--')\n",
    "    plt.axhline(y=np.mean(same_list[i][plot_from:]), color='b', linestyle='--')\n",
    "\n",
    "    plt.title('Accuracy Over Days - Using Day 0 Classifier')\n",
    "    plt.xlabel('Day #')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(diff_list)):\n",
    "    if np.mean(same_list[i]) < 0.55:\n",
    "        continue\n",
    "        \n",
    "    plt.figure(i)\n",
    "    # Start from which day to plot?\n",
    "    plot_from = 0\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), AE_list[i][plot_from:], label='AE diff day', color='g')\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), diff_list[i][plot_from:], label='bench diff day', color='r')\n",
    "    plt.plot(range(plot_from, plot_from + len(diff_list[i][plot_from:])), same_list[i][plot_from:], label='bench same day', color='b')\n",
    "\n",
    "    plt.axhline(y=np.mean(AE_list[i][plot_from:]), color='g', linestyle='--')\n",
    "    plt.axhline(y=np.mean(diff_list[i][plot_from:]), color='r', linestyle='--')\n",
    "    plt.axhline(y=np.mean(same_list[i][plot_from:]), color='b', linestyle='--')\n",
    "\n",
    "    plt.title('Accuracy Over Days - Using Day 0 Classifier')\n",
    "    plt.xlabel('Day #')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b7cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
